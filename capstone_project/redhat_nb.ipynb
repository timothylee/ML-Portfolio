{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.889441\ttrain-auc:0.889292\n",
      "Multiple eval metrics have been passed: 'train-auc' will be used for early stopping.\n",
      "\n",
      "Will train until train-auc hasn't improved in 5 rounds.\n",
      "[1]\teval-auc:0.898272\ttrain-auc:0.898143\n",
      "[2]\teval-auc:0.907268\ttrain-auc:0.90717\n",
      "[3]\teval-auc:0.915886\ttrain-auc:0.915834\n",
      "[4]\teval-auc:0.923916\ttrain-auc:0.92391\n",
      "[5]\teval-auc:0.931225\ttrain-auc:0.931244\n",
      "[6]\teval-auc:0.938026\ttrain-auc:0.938076\n",
      "[7]\teval-auc:0.94443\ttrain-auc:0.944521\n",
      "[8]\teval-auc:0.950463\ttrain-auc:0.950586\n",
      "[9]\teval-auc:0.956088\ttrain-auc:0.956243\n",
      "[10]\teval-auc:0.961248\ttrain-auc:0.961439\n",
      "[11]\teval-auc:0.965877\ttrain-auc:0.966104\n",
      "[12]\teval-auc:0.969952\ttrain-auc:0.970216\n",
      "[13]\teval-auc:0.973482\ttrain-auc:0.973778\n",
      "[14]\teval-auc:0.976494\ttrain-auc:0.976822\n",
      "[15]\teval-auc:0.979043\ttrain-auc:0.979407\n",
      "[16]\teval-auc:0.981181\ttrain-auc:0.981576\n",
      "[17]\teval-auc:0.982969\ttrain-auc:0.983394\n",
      "[18]\teval-auc:0.984461\ttrain-auc:0.984913\n",
      "[19]\teval-auc:0.985709\ttrain-auc:0.986184\n",
      "[20]\teval-auc:0.986756\ttrain-auc:0.987251\n",
      "[21]\teval-auc:0.987643\ttrain-auc:0.988155\n",
      "[22]\teval-auc:0.988401\ttrain-auc:0.988927\n",
      "[23]\teval-auc:0.989053\ttrain-auc:0.989592\n",
      "[24]\teval-auc:0.989624\ttrain-auc:0.990174\n",
      "[25]\teval-auc:0.990125\ttrain-auc:0.990686\n",
      "[26]\teval-auc:0.990572\ttrain-auc:0.991141\n",
      "[27]\teval-auc:0.990971\ttrain-auc:0.991547\n",
      "[28]\teval-auc:0.991329\ttrain-auc:0.991913\n",
      "[29]\teval-auc:0.991655\ttrain-auc:0.992244\n",
      "[30]\teval-auc:0.991953\ttrain-auc:0.992546\n",
      "[31]\teval-auc:0.992226\ttrain-auc:0.992823\n",
      "[32]\teval-auc:0.992476\ttrain-auc:0.993078\n",
      "[33]\teval-auc:0.992708\ttrain-auc:0.993312\n",
      "[34]\teval-auc:0.992921\ttrain-auc:0.993527\n",
      "[35]\teval-auc:0.99312\ttrain-auc:0.993728\n",
      "[36]\teval-auc:0.993305\ttrain-auc:0.993914\n",
      "[37]\teval-auc:0.993477\ttrain-auc:0.994088\n",
      "[38]\teval-auc:0.993638\ttrain-auc:0.99425\n",
      "[39]\teval-auc:0.993788\ttrain-auc:0.994401\n",
      "[40]\teval-auc:0.993929\ttrain-auc:0.994543\n",
      "[41]\teval-auc:0.994062\ttrain-auc:0.994675\n",
      "[42]\teval-auc:0.994186\ttrain-auc:0.9948\n",
      "[43]\teval-auc:0.994304\ttrain-auc:0.994917\n",
      "[44]\teval-auc:0.994415\ttrain-auc:0.995028\n",
      "[45]\teval-auc:0.99452\ttrain-auc:0.995132\n",
      "[46]\teval-auc:0.994619\ttrain-auc:0.995231\n",
      "[47]\teval-auc:0.994712\ttrain-auc:0.995324\n",
      "[48]\teval-auc:0.994801\ttrain-auc:0.995412\n",
      "[49]\teval-auc:0.994886\ttrain-auc:0.995496\n",
      "[50]\teval-auc:0.994966\ttrain-auc:0.995575\n",
      "[51]\teval-auc:0.995041\ttrain-auc:0.99565\n",
      "[52]\teval-auc:0.995113\ttrain-auc:0.995721\n",
      "[53]\teval-auc:0.995182\ttrain-auc:0.995789\n",
      "[54]\teval-auc:0.995247\ttrain-auc:0.995854\n",
      "[55]\teval-auc:0.995309\ttrain-auc:0.995915\n",
      "[56]\teval-auc:0.995368\ttrain-auc:0.995973\n",
      "[57]\teval-auc:0.995424\ttrain-auc:0.996029\n",
      "[58]\teval-auc:0.995478\ttrain-auc:0.996082\n",
      "[59]\teval-auc:0.995529\ttrain-auc:0.996132\n",
      "[60]\teval-auc:0.995577\ttrain-auc:0.99618\n",
      "[61]\teval-auc:0.995624\ttrain-auc:0.996225\n",
      "[62]\teval-auc:0.995668\ttrain-auc:0.996269\n",
      "[63]\teval-auc:0.995711\ttrain-auc:0.99631\n",
      "[64]\teval-auc:0.995751\ttrain-auc:0.99635\n",
      "[65]\teval-auc:0.99579\ttrain-auc:0.996388\n",
      "[66]\teval-auc:0.995827\ttrain-auc:0.996425\n",
      "[67]\teval-auc:0.995863\ttrain-auc:0.99646\n",
      "[68]\teval-auc:0.995897\ttrain-auc:0.996493\n",
      "[69]\teval-auc:0.99593\ttrain-auc:0.996525\n",
      "[70]\teval-auc:0.995961\ttrain-auc:0.996556\n",
      "[71]\teval-auc:0.995992\ttrain-auc:0.996585\n",
      "[72]\teval-auc:0.996021\ttrain-auc:0.996613\n",
      "[73]\teval-auc:0.996049\ttrain-auc:0.99664\n",
      "[74]\teval-auc:0.996075\ttrain-auc:0.996666\n",
      "[75]\teval-auc:0.996101\ttrain-auc:0.996691\n",
      "[76]\teval-auc:0.996126\ttrain-auc:0.996714\n",
      "[77]\teval-auc:0.996149\ttrain-auc:0.996737\n",
      "[78]\teval-auc:0.996172\ttrain-auc:0.996759\n",
      "[79]\teval-auc:0.996195\ttrain-auc:0.996781\n",
      "[80]\teval-auc:0.996216\ttrain-auc:0.996801\n",
      "[81]\teval-auc:0.996237\ttrain-auc:0.99682\n",
      "[82]\teval-auc:0.996256\ttrain-auc:0.996839\n",
      "[83]\teval-auc:0.996275\ttrain-auc:0.996857\n",
      "[84]\teval-auc:0.996294\ttrain-auc:0.996874\n",
      "[85]\teval-auc:0.996311\ttrain-auc:0.996891\n",
      "[86]\teval-auc:0.996328\ttrain-auc:0.996907\n",
      "[87]\teval-auc:0.996345\ttrain-auc:0.996922\n",
      "[88]\teval-auc:0.996361\ttrain-auc:0.996937\n",
      "[89]\teval-auc:0.996376\ttrain-auc:0.996951\n",
      "[90]\teval-auc:0.996391\ttrain-auc:0.996965\n",
      "[91]\teval-auc:0.996405\ttrain-auc:0.996978\n",
      "[92]\teval-auc:0.996418\ttrain-auc:0.99699\n",
      "[93]\teval-auc:0.996431\ttrain-auc:0.997002\n",
      "[94]\teval-auc:0.996444\ttrain-auc:0.997014\n",
      "[95]\teval-auc:0.996456\ttrain-auc:0.997025\n",
      "[96]\teval-auc:0.996467\ttrain-auc:0.997036\n",
      "[97]\teval-auc:0.996479\ttrain-auc:0.997046\n",
      "[98]\teval-auc:0.99649\ttrain-auc:0.997056\n",
      "[99]\teval-auc:0.9965\ttrain-auc:0.997066\n",
      "[100]\teval-auc:0.99651\ttrain-auc:0.997075\n",
      "[101]\teval-auc:0.99652\ttrain-auc:0.997084\n",
      "[102]\teval-auc:0.996529\ttrain-auc:0.997092\n",
      "[103]\teval-auc:0.996537\ttrain-auc:0.9971\n",
      "[104]\teval-auc:0.996546\ttrain-auc:0.997108\n",
      "[105]\teval-auc:0.996554\ttrain-auc:0.997116\n",
      "[106]\teval-auc:0.996562\ttrain-auc:0.997123\n",
      "[107]\teval-auc:0.99657\ttrain-auc:0.997131\n",
      "[108]\teval-auc:0.996577\ttrain-auc:0.997137\n",
      "[109]\teval-auc:0.996585\ttrain-auc:0.997144\n",
      "[110]\teval-auc:0.996591\ttrain-auc:0.997151\n",
      "[111]\teval-auc:0.996598\ttrain-auc:0.997157\n",
      "[112]\teval-auc:0.996604\ttrain-auc:0.997163\n",
      "[113]\teval-auc:0.996611\ttrain-auc:0.997169\n",
      "[114]\teval-auc:0.996617\ttrain-auc:0.997174\n",
      "[115]\teval-auc:0.996623\ttrain-auc:0.99718\n",
      "[116]\teval-auc:0.996628\ttrain-auc:0.997185\n",
      "[117]\teval-auc:0.996634\ttrain-auc:0.99719\n",
      "[118]\teval-auc:0.996639\ttrain-auc:0.997195\n",
      "[119]\teval-auc:0.996644\ttrain-auc:0.9972\n",
      "[120]\teval-auc:0.996649\ttrain-auc:0.997205\n",
      "[121]\teval-auc:0.996653\ttrain-auc:0.997209\n",
      "[122]\teval-auc:0.996658\ttrain-auc:0.997214\n",
      "[123]\teval-auc:0.996662\ttrain-auc:0.997218\n",
      "[124]\teval-auc:0.996666\ttrain-auc:0.997222\n",
      "[125]\teval-auc:0.99667\ttrain-auc:0.997226\n",
      "[126]\teval-auc:0.996674\ttrain-auc:0.99723\n",
      "[127]\teval-auc:0.996678\ttrain-auc:0.997234\n",
      "[128]\teval-auc:0.996682\ttrain-auc:0.997238\n",
      "[129]\teval-auc:0.996686\ttrain-auc:0.997241\n",
      "[130]\teval-auc:0.996689\ttrain-auc:0.997245\n",
      "[131]\teval-auc:0.996692\ttrain-auc:0.997248\n",
      "[132]\teval-auc:0.996696\ttrain-auc:0.997252\n",
      "[133]\teval-auc:0.996699\ttrain-auc:0.997255\n",
      "[134]\teval-auc:0.996702\ttrain-auc:0.997258\n",
      "[135]\teval-auc:0.996705\ttrain-auc:0.997261\n",
      "[136]\teval-auc:0.996708\ttrain-auc:0.997264\n",
      "[137]\teval-auc:0.996711\ttrain-auc:0.997267\n",
      "[138]\teval-auc:0.996714\ttrain-auc:0.99727\n",
      "[139]\teval-auc:0.996716\ttrain-auc:0.997273\n",
      "[140]\teval-auc:0.996719\ttrain-auc:0.997276\n",
      "[141]\teval-auc:0.996721\ttrain-auc:0.997278\n",
      "[142]\teval-auc:0.996724\ttrain-auc:0.997281\n",
      "[143]\teval-auc:0.996726\ttrain-auc:0.997283\n",
      "[144]\teval-auc:0.996728\ttrain-auc:0.997286\n",
      "[145]\teval-auc:0.996731\ttrain-auc:0.997288\n",
      "[146]\teval-auc:0.996733\ttrain-auc:0.997291\n",
      "[147]\teval-auc:0.996735\ttrain-auc:0.997293\n",
      "[148]\teval-auc:0.996737\ttrain-auc:0.997295\n",
      "[149]\teval-auc:0.996738\ttrain-auc:0.997297\n",
      "[150]\teval-auc:0.99674\ttrain-auc:0.9973\n",
      "[151]\teval-auc:0.996742\ttrain-auc:0.997302\n",
      "[152]\teval-auc:0.996744\ttrain-auc:0.997304\n",
      "[153]\teval-auc:0.996745\ttrain-auc:0.997306\n",
      "[154]\teval-auc:0.996747\ttrain-auc:0.997308\n",
      "[155]\teval-auc:0.996749\ttrain-auc:0.997309\n",
      "[156]\teval-auc:0.99675\ttrain-auc:0.997311\n",
      "[157]\teval-auc:0.996752\ttrain-auc:0.997313\n",
      "[158]\teval-auc:0.996753\ttrain-auc:0.997315\n",
      "[159]\teval-auc:0.996755\ttrain-auc:0.997317\n",
      "[160]\teval-auc:0.996756\ttrain-auc:0.997318\n",
      "[161]\teval-auc:0.996757\ttrain-auc:0.99732\n",
      "[162]\teval-auc:0.996758\ttrain-auc:0.997321\n",
      "[163]\teval-auc:0.99676\ttrain-auc:0.997323\n",
      "[164]\teval-auc:0.996761\ttrain-auc:0.997325\n",
      "[165]\teval-auc:0.996762\ttrain-auc:0.997326\n",
      "[166]\teval-auc:0.996763\ttrain-auc:0.997328\n",
      "[167]\teval-auc:0.996764\ttrain-auc:0.997329\n",
      "[168]\teval-auc:0.996765\ttrain-auc:0.99733\n",
      "[169]\teval-auc:0.996766\ttrain-auc:0.997332\n",
      "[170]\teval-auc:0.996767\ttrain-auc:0.997333\n",
      "[171]\teval-auc:0.996768\ttrain-auc:0.997334\n",
      "[172]\teval-auc:0.996768\ttrain-auc:0.997336\n",
      "[173]\teval-auc:0.996769\ttrain-auc:0.997337\n",
      "[174]\teval-auc:0.99677\ttrain-auc:0.997338\n",
      "[175]\teval-auc:0.996771\ttrain-auc:0.997339\n",
      "[176]\teval-auc:0.996772\ttrain-auc:0.997341\n",
      "[177]\teval-auc:0.996772\ttrain-auc:0.997342\n",
      "[178]\teval-auc:0.996773\ttrain-auc:0.997343\n",
      "[179]\teval-auc:0.996774\ttrain-auc:0.997344\n",
      "[180]\teval-auc:0.996774\ttrain-auc:0.997345\n",
      "[181]\teval-auc:0.996775\ttrain-auc:0.997346\n",
      "[182]\teval-auc:0.996775\ttrain-auc:0.997347\n",
      "[183]\teval-auc:0.996776\ttrain-auc:0.997348\n",
      "[184]\teval-auc:0.996776\ttrain-auc:0.997349\n",
      "[185]\teval-auc:0.996777\ttrain-auc:0.99735\n",
      "[186]\teval-auc:0.996777\ttrain-auc:0.997351\n",
      "[187]\teval-auc:0.996778\ttrain-auc:0.997352\n",
      "[188]\teval-auc:0.996778\ttrain-auc:0.997353\n",
      "[189]\teval-auc:0.996779\ttrain-auc:0.997354\n",
      "[190]\teval-auc:0.996779\ttrain-auc:0.997355\n",
      "[191]\teval-auc:0.99678\ttrain-auc:0.997355\n",
      "[192]\teval-auc:0.99678\ttrain-auc:0.997356\n",
      "[193]\teval-auc:0.99678\ttrain-auc:0.997357\n",
      "[194]\teval-auc:0.996781\ttrain-auc:0.997358\n",
      "[195]\teval-auc:0.996781\ttrain-auc:0.997359\n",
      "[196]\teval-auc:0.996781\ttrain-auc:0.99736\n",
      "[197]\teval-auc:0.996782\ttrain-auc:0.99736\n",
      "[198]\teval-auc:0.996782\ttrain-auc:0.997361\n",
      "[199]\teval-auc:0.996782\ttrain-auc:0.997362\n",
      "[200]\teval-auc:0.996782\ttrain-auc:0.997363\n",
      "[201]\teval-auc:0.996782\ttrain-auc:0.997363\n",
      "[202]\teval-auc:0.996783\ttrain-auc:0.997364\n",
      "[203]\teval-auc:0.996783\ttrain-auc:0.997365\n",
      "[204]\teval-auc:0.996783\ttrain-auc:0.997366\n",
      "[205]\teval-auc:0.996783\ttrain-auc:0.997366\n",
      "[206]\teval-auc:0.996783\ttrain-auc:0.997367\n",
      "[207]\teval-auc:0.996784\ttrain-auc:0.997368\n",
      "[208]\teval-auc:0.996784\ttrain-auc:0.997368\n",
      "[209]\teval-auc:0.996784\ttrain-auc:0.997369\n",
      "[210]\teval-auc:0.996784\ttrain-auc:0.99737\n",
      "[211]\teval-auc:0.996784\ttrain-auc:0.99737\n",
      "[212]\teval-auc:0.996784\ttrain-auc:0.997371\n",
      "[213]\teval-auc:0.996784\ttrain-auc:0.997371\n",
      "[214]\teval-auc:0.996784\ttrain-auc:0.997372\n",
      "[215]\teval-auc:0.996784\ttrain-auc:0.997373\n",
      "[216]\teval-auc:0.996784\ttrain-auc:0.997373\n",
      "[217]\teval-auc:0.996785\ttrain-auc:0.997374\n",
      "[218]\teval-auc:0.996785\ttrain-auc:0.997374\n",
      "[219]\teval-auc:0.996785\ttrain-auc:0.997375\n",
      "[220]\teval-auc:0.996785\ttrain-auc:0.997375\n",
      "[221]\teval-auc:0.996785\ttrain-auc:0.997376\n",
      "[222]\teval-auc:0.996785\ttrain-auc:0.997377\n",
      "[223]\teval-auc:0.996785\ttrain-auc:0.997377\n",
      "[224]\teval-auc:0.996785\ttrain-auc:0.997378\n",
      "[225]\teval-auc:0.996785\ttrain-auc:0.997378\n",
      "[226]\teval-auc:0.996785\ttrain-auc:0.997379\n",
      "[227]\teval-auc:0.996785\ttrain-auc:0.997379\n",
      "[228]\teval-auc:0.996785\ttrain-auc:0.99738\n",
      "[229]\teval-auc:0.996785\ttrain-auc:0.99738\n",
      "[230]\teval-auc:0.996785\ttrain-auc:0.997381\n",
      "[231]\teval-auc:0.996785\ttrain-auc:0.997381\n",
      "[232]\teval-auc:0.996785\ttrain-auc:0.997382\n",
      "[233]\teval-auc:0.996785\ttrain-auc:0.997382\n",
      "[234]\teval-auc:0.996785\ttrain-auc:0.997382\n",
      "[235]\teval-auc:0.996785\ttrain-auc:0.997383\n",
      "[236]\teval-auc:0.996785\ttrain-auc:0.997383\n",
      "[237]\teval-auc:0.996785\ttrain-auc:0.997384\n",
      "[238]\teval-auc:0.996785\ttrain-auc:0.997384\n",
      "[239]\teval-auc:0.996785\ttrain-auc:0.997385\n",
      "[240]\teval-auc:0.996784\ttrain-auc:0.997385\n",
      "[241]\teval-auc:0.996784\ttrain-auc:0.997386\n",
      "[242]\teval-auc:0.996784\ttrain-auc:0.997386\n",
      "[243]\teval-auc:0.996784\ttrain-auc:0.997386\n",
      "[244]\teval-auc:0.996784\ttrain-auc:0.997387\n",
      "[245]\teval-auc:0.996784\ttrain-auc:0.997387\n",
      "[246]\teval-auc:0.996784\ttrain-auc:0.997387\n",
      "[247]\teval-auc:0.996784\ttrain-auc:0.997388\n",
      "[248]\teval-auc:0.996784\ttrain-auc:0.997388\n",
      "[249]\teval-auc:0.996784\ttrain-auc:0.997389\n",
      "[250]\teval-auc:0.996784\ttrain-auc:0.997389\n",
      "[251]\teval-auc:0.996784\ttrain-auc:0.997389\n",
      "[252]\teval-auc:0.996784\ttrain-auc:0.99739\n",
      "[253]\teval-auc:0.996784\ttrain-auc:0.99739\n",
      "[254]\teval-auc:0.996783\ttrain-auc:0.99739\n",
      "[255]\teval-auc:0.996783\ttrain-auc:0.997391\n",
      "[256]\teval-auc:0.996783\ttrain-auc:0.997391\n",
      "[257]\teval-auc:0.996783\ttrain-auc:0.997392\n",
      "[258]\teval-auc:0.996783\ttrain-auc:0.997392\n",
      "[259]\teval-auc:0.996783\ttrain-auc:0.997392\n",
      "[260]\teval-auc:0.996783\ttrain-auc:0.997392\n",
      "[261]\teval-auc:0.996783\ttrain-auc:0.997393\n",
      "[262]\teval-auc:0.996783\ttrain-auc:0.997393\n",
      "[263]\teval-auc:0.996782\ttrain-auc:0.997393\n",
      "[264]\teval-auc:0.996782\ttrain-auc:0.997394\n",
      "[265]\teval-auc:0.996782\ttrain-auc:0.997394\n",
      "[266]\teval-auc:0.996782\ttrain-auc:0.997394\n",
      "[267]\teval-auc:0.996782\ttrain-auc:0.997395\n",
      "[268]\teval-auc:0.996782\ttrain-auc:0.997395\n",
      "[269]\teval-auc:0.996782\ttrain-auc:0.997395\n",
      "[270]\teval-auc:0.996782\ttrain-auc:0.997396\n",
      "[271]\teval-auc:0.996782\ttrain-auc:0.997396\n",
      "[272]\teval-auc:0.996781\ttrain-auc:0.997396\n",
      "[273]\teval-auc:0.996781\ttrain-auc:0.997396\n",
      "[274]\teval-auc:0.996781\ttrain-auc:0.997397\n",
      "[275]\teval-auc:0.996781\ttrain-auc:0.997397\n",
      "[276]\teval-auc:0.996781\ttrain-auc:0.997397\n",
      "[277]\teval-auc:0.996781\ttrain-auc:0.997398\n",
      "[278]\teval-auc:0.996781\ttrain-auc:0.997398\n",
      "[279]\teval-auc:0.996781\ttrain-auc:0.997398\n",
      "[280]\teval-auc:0.99678\ttrain-auc:0.997398\n",
      "[281]\teval-auc:0.99678\ttrain-auc:0.997399\n",
      "[282]\teval-auc:0.99678\ttrain-auc:0.997399\n",
      "[283]\teval-auc:0.99678\ttrain-auc:0.997399\n",
      "[284]\teval-auc:0.99678\ttrain-auc:0.997399\n",
      "[285]\teval-auc:0.99678\ttrain-auc:0.9974\n",
      "[286]\teval-auc:0.996779\ttrain-auc:0.9974\n",
      "[287]\teval-auc:0.996779\ttrain-auc:0.9974\n",
      "[288]\teval-auc:0.996779\ttrain-auc:0.9974\n",
      "[289]\teval-auc:0.996779\ttrain-auc:0.997401\n",
      "[290]\teval-auc:0.996779\ttrain-auc:0.997401\n",
      "[291]\teval-auc:0.996779\ttrain-auc:0.997401\n",
      "[292]\teval-auc:0.996778\ttrain-auc:0.997401\n",
      "[293]\teval-auc:0.996778\ttrain-auc:0.997402\n",
      "[294]\teval-auc:0.996778\ttrain-auc:0.997402\n",
      "[295]\teval-auc:0.996778\ttrain-auc:0.997402\n",
      "[296]\teval-auc:0.996778\ttrain-auc:0.997402\n",
      "[297]\teval-auc:0.996778\ttrain-auc:0.997402\n",
      "[298]\teval-auc:0.996778\ttrain-auc:0.997403\n",
      "[299]\teval-auc:0.996777\ttrain-auc:0.997403\n",
      "[300]\teval-auc:0.996777\ttrain-auc:0.997403\n",
      "[301]\teval-auc:0.996777\ttrain-auc:0.997403\n",
      "[302]\teval-auc:0.996777\ttrain-auc:0.997404\n",
      "[303]\teval-auc:0.996777\ttrain-auc:0.997404\n",
      "[304]\teval-auc:0.996777\ttrain-auc:0.997404\n",
      "[305]\teval-auc:0.996776\ttrain-auc:0.997404\n",
      "[306]\teval-auc:0.996776\ttrain-auc:0.997404\n",
      "[307]\teval-auc:0.996776\ttrain-auc:0.997405\n",
      "[308]\teval-auc:0.996776\ttrain-auc:0.997405\n",
      "[309]\teval-auc:0.996776\ttrain-auc:0.997405\n",
      "[310]\teval-auc:0.996776\ttrain-auc:0.997405\n",
      "[311]\teval-auc:0.996775\ttrain-auc:0.997405\n",
      "[312]\teval-auc:0.996775\ttrain-auc:0.997406\n",
      "[313]\teval-auc:0.996775\ttrain-auc:0.997406\n",
      "[314]\teval-auc:0.996775\ttrain-auc:0.997406\n",
      "[315]\teval-auc:0.996774\ttrain-auc:0.997406\n",
      "[316]\teval-auc:0.996774\ttrain-auc:0.997406\n",
      "[317]\teval-auc:0.996774\ttrain-auc:0.997407\n",
      "[318]\teval-auc:0.996774\ttrain-auc:0.997407\n",
      "[319]\teval-auc:0.996774\ttrain-auc:0.997407\n",
      "[320]\teval-auc:0.996773\ttrain-auc:0.997407\n",
      "[321]\teval-auc:0.996773\ttrain-auc:0.997407\n",
      "[322]\teval-auc:0.996773\ttrain-auc:0.997407\n",
      "Stopping. Best iteration:\n",
      "[317]\teval-auc:0.996774\ttrain-auc:0.997407\n",
      "\n",
      "0.996772831138\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from PreprocessingScripts import *\n",
    "\n",
    "# import data from files\n",
    "act_train_data = pd.read_csv(\n",
    "    \"c:/ml/redhat/input/act_train.csv\",\n",
    "    dtype = {\n",
    "        'people_id': np.str, \n",
    "        'activity_id': np.str, \n",
    "        'outcome': np.int8\n",
    "    }, \n",
    "    parse_dates=['date']\n",
    ")\n",
    "\n",
    "people_data = pd.read_csv(\n",
    "    \"c:/ml/redhat/input/people.csv\",\n",
    "    dtype = {\n",
    "        'people_id': np.str, \n",
    "        'activity_id': np.str, \n",
    "        'char_38': np.int32\n",
    "    }, \n",
    "    parse_dates=['date']\n",
    ")\n",
    "\n",
    "# massage data so that it's easier to work with and analyze\n",
    "act_train_data  = act_data_treatment(act_train_data)\n",
    "people_data = act_data_treatment(people_data)\n",
    "\n",
    "# merge activity file with people file using people_id key\n",
    "train = act_train_data.merge(\n",
    "    people_data, \n",
    "    on='people_id', \n",
    "    how='left', \n",
    "    left_index=True\n",
    ")\n",
    "\n",
    "del act_train_data\n",
    "del people_data\n",
    "\n",
    "# sort data by people_id, [1] has one value of 1, means True for people_id\n",
    "train=train.sort_values(['people_id'], ascending=[1])\n",
    "\n",
    "# fill blanks with NA\n",
    "train.fillna('NA', inplace=True)\n",
    "\n",
    "# remove outcome from feature set\n",
    "y = train.outcome\n",
    "train=train.drop('outcome',axis=1)\n",
    "train_columns = train.columns.values\n",
    "features = list(set(train_columns))\n",
    "\n",
    "# categorical columns in merged dataset\n",
    "categorical=['group_1',\n",
    "             'activity_category',\n",
    "             'char_1_x',\n",
    "             'char_2_x',\n",
    "             'char_3_x',\n",
    "             'char_4_x',\n",
    "             'char_5_x',\n",
    "             'char_6_x',\n",
    "             'char_7_x',\n",
    "             'char_8_x',\n",
    "             'char_9_x',\n",
    "             'char_10_x',\n",
    "             'char_2_y',\n",
    "             'char_3_y',\n",
    "             'char_4_y',\n",
    "             'char_5_y',\n",
    "             'char_6_y',\n",
    "             'char_7_y',\n",
    "             'char_8_y',\n",
    "             'char_9_y'\n",
    "            ]\n",
    "\n",
    "# reduce dimensionality of categorical features\n",
    "for category in categorical:\n",
    "    train=reduce_dimen(train,category,9999999)\n",
    "    \n",
    "# change variable name to X for convenience\n",
    "X=train\n",
    "del train\n",
    "    \n",
    "X=X.sort_values(['people_id'], ascending=[1])\n",
    "\n",
    "# drop non-feature columns\n",
    "X = X[features].drop(['people_id', 'activity_id'], axis = 1)\n",
    "\n",
    "not_categorical=[]\n",
    "\n",
    "for category in X.columns:\n",
    "    if category not in categorical:\n",
    "        not_categorical.append(category)\n",
    "        \n",
    "# split X,y into training and validation set\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "# convert categorical columns to numerical\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc=enc.fit(X[categorical])\n",
    "X_train_cat_sparse=enc.transform(X_train[categorical])\n",
    "X_val_cat_sparse=enc.transform(X_val[categorical])\n",
    "\n",
    "# stack sparse matrices\n",
    "from scipy.sparse import hstack\n",
    "X_train_sparse=hstack((X_train[not_categorical], X_train_cat_sparse))\n",
    "X_val_sparse=hstack((X_val[not_categorical], X_val_cat_sparse))\n",
    "\n",
    "dTrain = xgb.DMatrix(X_train_sparse,label=y_train)\n",
    "dValidate = xgb.DMatrix(X_val_sparse,label=y_val)\n",
    "\n",
    "# set classifier parameters\n",
    "param = {'max_depth':11, 'eta':0.02, 'silent':1, 'objective':'binary:logistic' }\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'\n",
    "param['subsample'] = 0.8\n",
    "param['colsample_bytree']= 0.8\n",
    "\n",
    "# default booster 'gbtree' doesn't perform as well as 'gblinear'\n",
    "param['booster'] = \"gblinear\"\n",
    "\n",
    "# train model\n",
    "watchlist = [(dValidate,'eval'), (dTrain,'train')]\n",
    "num_round = 400\n",
    "early_stopping_rounds=5\n",
    "\n",
    "evals_result = {}\n",
    "\n",
    "bst = xgb.train(\n",
    "    param, \n",
    "    dTrain, \n",
    "    num_round, \n",
    "    watchlist,\n",
    "    early_stopping_rounds=early_stopping_rounds,\n",
    "    evals_result=evals_result\n",
    ")\n",
    "\n",
    "# validate\n",
    "yPrediction = bst.predict(dValidate)\n",
    "print(roc_auc_score(y_val, yPrediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.987940874351204"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.996772831138 - 0.966989848292) * 100 / 0.996772831138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
